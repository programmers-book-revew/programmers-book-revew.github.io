---
layout: post
title: Making Software
categories: rank_4
tags: [ソフトウェア工学, oreilly]
---


<div class="book"><div class="book_image"><a href="http://www.amazon.co.jp/dp/4873115116"><img src="/images/making_software.jpg"></img></a></div><div class="book_info">/オライリージャパン</div><div class="clear"></div></div>

ソフトウェア工学について何もしらずかつ懐疑的な自分にとっておもしろい本で楽しく読めた。以下のような、一見不思議とも思える内容や、何となくそう思っていたけどどこにも載っていないような内容が書かれており興味深かったので。 

* コードの中身を見るよりも、どのような組織でそのコードが書かれたかを見た方がエラーがどこにあるか分かる(cf. p.190とp.400のメモ) 
* ファンクション法などによる見積り方法は、専門家の判断による見積りよりも優れていない(cf. p.44のメモ) 
* コードカバレジが多くなればリリースの品質が向上する、とは言えない。(cf. p.393のメモ) 
* コピーペーストが一概に悪いとは言えない(cf. p.501のメモ) 
* ソースコードの複雑度を調べなくてもソースコードの行数だけで十分(cf. 134のメモ) 
* TDD(Test-Driven Development)が有効と言うエビデンスはない(cf. p.201のメモ) 
* プログラミング言語の差よりも、プログラマの差の方が重要。(cf. p.241のメモ) 
* コードレビューを会議でやるのは無駄(cf. p.312のメモ) 
* パーティション、共同作業空間、個室の中で最悪なのはパーティション(cf. p.328のメモ) 
* APIの使いやすさを測定して改善したケースがある(cf. p.524のメモ) 

エラーがどこにありそうかの研究なんて意味があるのだろうか。このソースにバグがあると言われてもどこにあるのか分からなければ意味が無い気がする。何が問題かすら分からないのだからバグの見つける方法が無いと思うから。そして何の問題かが明かになるのは、実際にバグが出たときである。 

我々は取れるデータからすぐ「量的エビデンス」的な(cf. p.21のメモ)に走りやすいが、その基礎となる理論もしくは法則(質的エビデンスと言えるのか?)が無いのであればあまりその研究に価値はないのではないかと感じた。少なくてもどちらの立場で研究してそれは何故かを言えるようにしなくては。 

この本のタイトルは当初Beautiful Evidenceとしたかったのではないか(原題はMaking Software: What Really Works, and Why We Believe It)。 

以下、自分用メモ <!--more-->

> フロアーからの「なぜ“ピープルウェア”の主張がアジャイル開発方法論に受け入れられるまでにこれほどまでの時間がかかったのか」という質問に対して、デマルコが「すべてベームが悪い」と答えたのです。その趣旨は、「私たちはベームの“ソフトウェア工学の経済学”のおかげで、ソフトウェアの不良の修正にかかるコストは、修正作業が開発ライフサイクルの後になるにつれて指数関数的に増えるので、要求や仕様はできるだけ上流で確定することが正しいと洗脳されてしまった」というものでした。これでウォーターフォールに“お墨付き”が与えられてしまったというのです。 
それに対してベームは、なんと合意しました。そして、ウォーターフォールが妥当だったのは、宇宙システムや軍用システムのように、ユーザの要求がきっちり定義できたときだけだった。1980年代は様相が変わったと述べていたのです。(p. v) 

> 量的エビデンス対質的エビデンス: 誤った二項対立 
研究に置ける議論では、調査が量的なものか質的なものかを区別するのが普通です。大まかに言うと、その違いは感心の対象とする問いにあります。量的調査は測定を中心とし、、「比較(comparison)」の質問(AはBより速いか?)、「もし～なら(if)」の問題(もしAが変わったらBは変わるか?)、「どれだけ(how much)」の問題(開発者はデバッグにどれだけの時間を費やすか?)を問うのが普通です。対照的に、質的調査は記述と分類に関係し、「なぜ(why)」の問題(なぜAはBより学びやすいか?)、「どうやって(how)」の問題(開発者はどうやって、どんな方法でデバッグにアプローチするか?)を問います。(p.21) 
まとめると、量的な調査の威力は、状況を少量の簡潔な記述で補足でき、そのため物事を非常に明解にできる場合がある、という点です。一方その不利な点は、多くの情報を無視してしまうため、結果が本当に何を意味しているのか、その結果が摘要可能なのはどの場合かの判断が難しいことが多いことです。質的な研究の威力は、その結果が現実世界の複雑さを反映し明かにしてくれる点です。その不利な点は、そのために評価がひどく難しいことです。どんな調査結果も、実権の範囲が一般化できないような狭いものであったり、観察の状況があまりに異なっているなどのために、その結果が現実世界のコンテキストとどう対応しているかが明らかでないなら、現実世界に適用することは難しいでしょう。(p.22) 

> その結果は、コストモデルによる見積りが専門家の判断による見積りよりも優るはずだ、という視点とは相違したものだったのです。(p.44) 

> 1976年から2001年にかけて、私たちは多数の間違いを犯しつつも、多くのことを学びました。間違いとしては、次のようなものがありました。 
o 環境を完全に理解する前に評価しようと試みた 
o ゴールおよびモデル主導でなくデータ主導だった 
o 他所の環境から導かれた他人のモデルを引き合いにして私たち自身の環境を説明した(p.67) NASAのソフトウェア工学研究所SEL 

> 実務環境におけるソフトウェア工学への科学的手法の適用プロセスという道のりを精選した形でお話ししましょう。 ... 

> 1. 適切なモデルとメトリクスに基づき、現在のプロジェクトとその環境を「特徴づける」(私たちの世界はどのように見えるか?) 
2. うまく実行されたプロジェクトの効率やその改良に関して「定量化可能な目標を設定する」(私たちの世界について何が知りたいか、そして何を成し遂げたいか?) 
3. 現在のプロジェクトに対して、「プロセスモデルの選択」、およびそれをサポートするメソッドとツールの選択を行う(この環境でこの目標のためにはどのプロセスがうまくいくか?) 
4. 「プロセスを実行」し、製品を構築し、データの収集・検証・分析を行って活動の適切さに関するリアルタイムのフィードバックを提供する(選んだプロセスの適用を通じて何が起きるか?) 
5. 「データを分析」して現在の実践を評価し、問題点を見極め、発見を記録し、将来のプロジェクト改善のための推奨点をまとめる(提案されたソリューションがどの程度うまくいったか、足らなかったのは何か、どう直すべきか?) 
6. 経験したことがらを、更新・洗練を行ったモデルの形、および今回や以前のプロジェクトから得たその他の構造化知識の形で、「パッケージ化する」。そして将来のプロジェクトで再利用できるように、経験データベースに保存する。(どうやって私たちが学んだことを組織に統合するか?) 
(p.68) 4, 5が弱いか。これらを何回も回すのも重用なはず。 

> ソフトウェア開発で最も重要なことは、プログラマが使うツールや技法ではなく、プログラマ自身の品質である。 -- ロバート・グラス「ソフトウェア開発55の真実と10のウソ」真実1 
プログラマ個人を分析した研究によると、最も優秀なプログラマは最悪に比べ、28倍優れている。給与が能力を反映していないとすると、優秀なプログラマは、最高の掘り出し物と言える。 -- ロバート・グラス「ソフトウェア開発55の真実と10のウソ」真実2 (p.77) 

> * 優秀なソフトウェア開発者であるとはどういう意味なのか、あなたは実際に定義できますか? 
ソフトウェア開発の一部のタスク(プログラミングなど)については、間もなく得られそうだけど、他のタスク(ソフトウェアの工数見積り)については、優れた能力を発揮する人はどのような人かを定義するのがずっと難しい 
* できるなら、ある開発者が他の人よりも優秀だということを、確実かつ効率よく見極める方法は見つけられますか? 
ある種のタスクについては、専門性やタスクの困難さを測定できそうですが、他の種類のタスクについては、まだ道のりはずっと長そうです。 
* できないなら、その代替としてツールや技術に注力すべきでしょうか? 
重要なスキルはツールや手法をマスターするスキルに変更されます。これが、ソフトウェア工数見積もりのように困難なタスクを、整合性があるとまでは言えないとしても、少なくとも不整合がより小さいタスクに変換する、1つの方法かもしれません。 
(p.78とp.98) 

> C言語で書かれた非ヘッダファイルに対しては、すべての複雑度メトリクスがコード行数と高い相関を示すため、わざわざ複雑なメトリクスを使っても、単にコード行数では測れないような情報はもたらされない(p.134) 

> コンウェイの法則: (広義の)システムを設計する組織はどんな組織でも、その組織のコミュニケーション構造と瓜二つの構造を持った設計をしてしまうものである。 
逸話の形のエビデンスとして、コンウェイは次のような例を引いています。研究の下請けをやっている組織に8人の人がいて、COBOLとALGOLのコンパイラを開発しました。最初に作業の難しさや所要時間の見積をした結果、5人がCOBOLの仕事に、3人がALGOLに仕事に割り当てられました。その結果製作されたCOBOLコンパイラは5つのフェーズ、ALGOLコンパイラは3つのフェーズを持つようなものでした。(p.179) 

> エラー予測は、組織構造をモデルとしたものが、他のモデル(コードの変更量、コードの複雑さ、依存関係、テストカバレッジ、リリース前のバグ)よりも正確に出る。(p.190 表11-1) 

> TDDの有効性 

> * 内部品質: 確実な効果はないことを示しています。TDDは一部のメトリクス(複雑性と再利用)に関して対照群より良い結果を出しているようですが、他のメトリクス(結合度と凝縮度)はTDD治療をすると悪化することがあります。 
* 外部品質: 改善することを示すエビデンスがある程度あります。ただし、商業プロジェクトと制御実験における支持のエビデンスは、厳密な実験構成のもの(L2とL3)に限定すると無くなってしまいます。 
* 生産性: TDDを採用すると、険しい学習曲線が必須であり最初は生産性が落ち込む可能性があると多くの人が認めている一方で、長期的には生産性が向上するという合意はありません。<snip>臨床試験で得られた有効なエビデンスは、TDDは生産性に関して確実な効果を持たないことを示しています。 
* テスト品質: 少なくとも悪くなることはなく、他の代替アプローチよりも良好な場合も多そうだ、ということになります。 
(p.201以降を適当に抜粋) 

> * プログラミング言語に関して言えば、何らかのテキスト処理(やその類の一般的な活動)を実行する小さなプログラムに対しては少なくとも、従来の静的な言語よりもスクリプト言語の方が生産的だと言っても安全でしょう。 
* そのようなプログラムの効率については、誤った言語の選択を避けることよりも、誤ったプログラマを避けることの方が通常ははるかに大切です。この点(および使うべき言語)を正しくする方法は多数あります。 
* Web開発のプラットフォームに関して、教科書通りのWebベースのシステムを有能なチームが開発する場合には、どのようなフレームワークを用い、チームがそのフレームワークをどれくらいマスターしているかが、使用する言語よりもずっと重要です。(p.241) 

> 多くのチームはペアプログラミングを利用することで製品の品質が改善したと報告している。生産性(人月単位のコード行数)は減少したという報告や複雑なタスクをこなすときはプラスの効果があるという報告がある。 
(p.297を適当に要約) 

> コードレビュー 

> * 60分後は欠陥発見の効率が急激に落ち込むのでやっても無駄。 
* レビュー速度は400～500LOC/時を越えると、欠陥密度は高くならないので、速くしすぎてもだめ 
* 300～500LOCあたりで欠陥密度が下がるので大きいとダメ 
* 各自で見つけるバグの割合: ミーティングで見つけるバグの割合は、96:4なのでミーティングは不要 
* 事前にセルフチェックをするとチェックなしで外部に指摘される時の半数を自分で見つけられる。 
(p.312以降を適当に抜粋) 

> 「共同作業場か、閉じるドアか?」に対する答えは「はい」です。つまり、両者は連続スペクトルの両極端にあるにも関わらず、双方のレイアウトが、現在標準的なパーティションレイアウトに対する大きな改善をもたらすのです。 
パーティションの問題は、それがここまで議論してきた2つの極端なレイアウトが持つ欠点のほとんどを兼ね備えているうえに、これらの長所のほとんどは持っていない、ということです。第一に、パーティションでは個室のように孤立できませんから、近くの会話で邪魔されたり注意が逸らされることが頻繁にあります。ですがパーティションはまったくの共有空間でもないので、共同作業場のような、常に互いにコーディネーションしたり意識しあえる場というわけでもありません。私の知る限りでは、ソフトウェア開発作業のための他のあらゆる選択肢よりもパーティションの方が優れている、ということを示すエビデンスを提示する文献はまったく存在しません。とにかく可能な限り、パーティションは避けるべきです。集中できること、もしくはコーディネーションできることの、いずれかを選択してください。どちらも選ばないというのは、かなり馬鹿げたことです。(p.328) 

> * 1番の人は最低の人に比べて約10倍の能率を実現すると期待できる 
* 1番の人は中央値の人の約2.5倍の能率を実現すると期待できる 
* 中央値より良い半数の人たちは、残りの半数の人たちより2倍以上優ると期待できる 
より重要なこととして、デマルコとリスターは、プログラミング言語、経験年数、給料、欠陥数に基づいては、誰が1番であるかを予測できないことを発見したのです。1つの強い余因子は、どこの場所で作業したか、ということでした。...デマルコとリスターは、これら驚くべき結果は相関があるというエビデンスに過ぎず、因果関係のエビデンスとは言えないことを認めています。彼らのはこう書いています。「(ここに)示したデータは、より良い作業場がより高い能力を示す人たちの助けになるであろうことを、厳密には証明はしていない。ただ単に、より高い能率で仕事する人たちは、より良い作業場を提供する組織に引き寄せられる傾向があることを示しているのかもしれない。...」(p.323) 

> よりカバレジが多くなれば、コード中のエラーをより多く見つけられ、それが修正されれば、リリースの品質が向上する、という主張もあり得ます。この仮定は広く信じられていますが、カバレジが多くなったときに欠陥が減る結果になることを示すエビデンスはほとんど無いのが実状です。(p.393) 

> 組織に関するメトリクスがソフトウェア品質の予測因子として効果的に利用可能なことを示しています。精度は86.2%、再現率は84%です。これは、私たちのこれまでの研究からすると、エラー予測に関する最も良い再現率の値だと言えます。このことが、組織のチーム構造を理解することがソフトウェアの品質について予測し理解する上での重大要因だというエビデンスを提供してくれます。このように解釈できるのは、組織に関するメトリクスが、実際のコードに対するメトリクスよりもずっと良くコードの品質を示しているからです。(p.400) 

> コードペーストされる場合 

> * ハードウェアの違い: ドライバなど共通なコンポーネントとしてくくり出すのが難しい 
* プラットフォームの違い: APIの実装がOSなどで異なっている場合 
* パラメタ化コード: Javaのジェネリクスが言語仕様に無かった時などプログラミング言語の問題 
* 常用句など: JavaのSwingなどボタンをcreateし、それをコンテナに追加し、リスナで動作を割り当てるなどおプログラミングイデオムなど 
(p.501以降を適当に要約) 

> Visual Studio IDEの設計時に用いた3つのペルソナ: 

> * 便宜的開発者: さっさと実験してみる、タスク中心のアプローチ。高レベルの具体的なコンポーネントを多用するなどの習慣が特徴 
* 実践的開発者: コード中心のアプローチと、(リファクタリングツール、ユニットテストツールなどの)自分が書くコードの頑健さや正しさに焦点を当てさせてくれるツールを用いることが特徴 
* 体系的開発者: 開発に対する防御的アプローチと、どのような技術でもそれを使った開発に着手するまでに深く理解する必要があることが特徴(p.524) 
すべてのペルソナに対応したAPIを設計するという問題の1つの方法は、APIが使われると期待されるシナリオと、そのシナリオを実行すると考えられる開発者のタイプに注目することです。多くの場合、シナリオが決まれば開発者のタイプも決まるでしょうから、そのシナリオに対応してどのような種類のAPIを設計すべきかも決まるでしょう。(p.527)
